{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/home/richhiey/Desktop/workspace/academics/courses/semester_4/Advanced Topics in Machine Learning/course_project\"\n",
    "CORPUS_PATH = os.path.join(BASE_PATH, \"Gutenberg_English_Fiction_1k\")\n",
    "DATA_PATH = os.path.join(CORPUS_PATH, \"Gutenberg_19th_century_English_Fiction\")\n",
    "FEATURES_PATH = os.path.join(BASE_PATH, \"ATiML-Project\", \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look at the merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Detective and Mystery\n",
       "1                   Literary\n",
       "2                   Literary\n",
       "3            Western Stories\n",
       "4                   Literary\n",
       "5                   Literary\n",
       "6      Detective and Mystery\n",
       "7                   Literary\n",
       "8                   Literary\n",
       "9                   Literary\n",
       "10                  Literary\n",
       "11                  Literary\n",
       "12                  Literary\n",
       "13                  Literary\n",
       "14                  Literary\n",
       "15          Ghost and Horror\n",
       "16                  Literary\n",
       "17                  Literary\n",
       "18                  Literary\n",
       "19                  Literary\n",
       "20     Detective and Mystery\n",
       "21                  Literary\n",
       "22                  Literary\n",
       "23                  Literary\n",
       "24                  Literary\n",
       "25                  Literary\n",
       "26                  Literary\n",
       "27                  Literary\n",
       "28                  Literary\n",
       "29                  Literary\n",
       "               ...          \n",
       "964                 Literary\n",
       "965                 Literary\n",
       "966                 Literary\n",
       "967                 Literary\n",
       "968        Christmas Stories\n",
       "969    Detective and Mystery\n",
       "970    Detective and Mystery\n",
       "971    Detective and Mystery\n",
       "972    Detective and Mystery\n",
       "973    Detective and Mystery\n",
       "974                 Literary\n",
       "975                 Literary\n",
       "976        Sea and Adventure\n",
       "977    Detective and Mystery\n",
       "978                 Literary\n",
       "979                 Literary\n",
       "980                 Literary\n",
       "981                 Literary\n",
       "982        Sea and Adventure\n",
       "983                 Literary\n",
       "984                 Literary\n",
       "985                 Literary\n",
       "986    Detective and Mystery\n",
       "987                 Literary\n",
       "988                 Literary\n",
       "989                 Literary\n",
       "990                 Literary\n",
       "991    Detective and Mystery\n",
       "992    Detective and Mystery\n",
       "993                 Literary\n",
       "Name: guten_genre, Length: 994, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMN_NAMES = [\n",
    "    'Filename',\n",
    "    'Number of Named People',\n",
    "    'Number of Named Places',\n",
    "    'Number of Named Organizations',\n",
    "    'Number of Sentences',\n",
    "    'Female Orientation',\n",
    "    'Male Orientation',\n",
    "    'Positive Sentiment',\n",
    "    'Negative Sentiment',\n",
    "    'Objective Sentiment',\n",
    "    'Number of Words',\n",
    "    'Number of Paragraphs',\n",
    "    'Relative Punctuation',\n",
    "    'Number of Dialogs',\n",
    "    'Number of Sentences with Dialogs'  \n",
    "]\n",
    "all_features = pd.read_csv(os.path.join(FEATURES_PATH, \"all_features_raw.csv\"), usecols=COLUMN_NAMES)\n",
    "meta_data = pd.read_csv(os.path.join(CORPUS_PATH, \"master996.csv\"), sep=\";\", header=0, encoding='latin1')\n",
    "merged_data = pd.merge(all_features, meta_data, left_on=\"Filename\", right_on=\"book_id\")\n",
    "merged_data[\"guten_genre\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset and labels to be used for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem that we face with the dataset, even after extracting explainable features, is that the output classes are imbalanced. The number of labeled instances for each of the classes is shown below:\n",
    "\n",
    "Literary:**792**\n",
    "\n",
    "Detective and Mystery:**111**\n",
    "\n",
    "Sea and Adventure:**36**\n",
    "\n",
    "Western Stories:**18**\n",
    "\n",
    "Love and Romance:**18**\n",
    "\n",
    "Ghost and Horror:**6**\n",
    "\n",
    "Humorous and Wit and Satire:**6**\n",
    "\n",
    "Christmas Stories:**5**\n",
    "\n",
    "Allegories:**2**\n",
    "\n",
    "As we can see, the last 4 entries seem outnumbered compared to the first. The label \"Allegories\" specially has only 2 labeled instances corresponding to it. I don't know how useful it could be predict such a class. In my opinion, it would be better to skip this class and focus on the others.\n",
    "\n",
    "In the case of \"Christmas Stories, \"Humor..\", and \"Ghost and Horror\", we have counts of 6, 6 and 5 respectively. Hence, I allowed for the possibility of duplicates and upsampled to get 20 instances in each class. This is a simple hack which increases the signal strength for any learning algorithm for a particular class.\n",
    "\n",
    "Similarly, we round off \"Love and Romance\" and \"Western Stories\" to 40 instances and \"Sea and Adventure\" to 60 instances by upsampling.\n",
    "\n",
    "For the other two majority classes \"Literary\" and \"Detective and Mystery\", we do not upsample.\n",
    "\n",
    "Overall, by upsampling, the dataset now looks something like this- \n",
    "\n",
    "Literary:**792**\n",
    "\n",
    "Detective and Mystery:**111**\n",
    "\n",
    "Sea and Adventure:**60**\n",
    "\n",
    "Western Stories:**40**\n",
    "\n",
    "Love and Romance:**40**\n",
    "\n",
    "Ghost and Horror:**20**\n",
    "\n",
    "Humorous and Wit and Satire:**20**\n",
    "\n",
    "Christmas Stories:**20**\n",
    "\n",
    "I don't know whether this is the right way to solve a class imbalance, but it seemed like a reasonable approach to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "COLUMNS_TO_DROP = [\"Filename\", \"Book_Name\", \"book_id\", \"Author_Name\", \"guten_genre\"]\n",
    "\n",
    "# THIS METHOD IS A PROBLEM - Our classes are super imbalanced, so doing a random split might \n",
    "# lead to some classes not even being in the test or train set\n",
    "labels = merged_data[['guten_genre']]\n",
    "data = merged_data.drop(COLUMNS_TO_DROP, axis=1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_train, x_test, y_train, y_test = train_test_split(min_max_scaler.fit_transform(data), labels, stratify=labels, test_size=0.2)\n",
    "\n",
    "# Custom splitting of classes is needed!\n",
    "def create_training_and_test_sets(labeled_instances, test_size, resample_num):\n",
    "    resampled = resample(\n",
    "        labeled_instances, \n",
    "        replace=True,\n",
    "        n_samples=resample_num,\n",
    "        random_state=123\n",
    "    )\n",
    "    return train_test_split(resampled, test_size=test_size)\n",
    "\n",
    "train_dataset = pd.DataFrame() \n",
    "test_dataset = pd.DataFrame()\n",
    "\n",
    "# Skipping label=Allegories since there are only two instances\n",
    "labels = [\n",
    "    \"Detective and Mystery\",\n",
    "    \"Literary\",\n",
    "    \"Christmas Stories\",\n",
    "    \"Western Stories\",\n",
    "    \"Sea and Adventure\",\n",
    "    \"Love and Romance\",\n",
    "    \"Humorous and Wit and Satire\",\n",
    "    \"Ghost and Horror\"\n",
    "]\n",
    "\n",
    "for label in labels:\n",
    "    sliced_dataset = merged_data[merged_data.guten_genre == label]\n",
    "    if (len(sliced_dataset) < 10):\n",
    "        # If count is very small, then upsample\n",
    "        train_set, test_set = create_training_and_test_sets(sliced_dataset, 0.3, 20)\n",
    "    elif (len(sliced_dataset) < 20):\n",
    "        train_set, test_set = create_training_and_test_sets(sliced_dataset, 0.3, 40)\n",
    "    elif (len(sliced_dataset) < 40):\n",
    "        # If count is less than 100, then resample to 50 \n",
    "        train_set, test_set = create_training_and_test_sets(sliced_dataset, 0.3, 60)\n",
    "    else:\n",
    "        # If count is very large, then split directly\n",
    "        train_set, test_set = train_test_split(sliced_dataset, test_size=0.3)\n",
    "    train_dataset = pd.concat([train_dataset, train_set])\n",
    "    test_dataset = pd.concat([test_dataset, test_set])\n",
    "\n",
    "\n",
    "x_train = train_dataset.drop(COLUMNS_TO_DROP, axis=1)\n",
    "x_test = test_dataset.drop(COLUMNS_TO_DROP, axis=1)\n",
    "x_train = pd.DataFrame(min_max_scaler.fit_transform(x_train))\n",
    "x_test = pd.DataFrame(min_max_scaler.fit_transform(x_test))\n",
    "y_train = train_dataset[[\"guten_genre\"]]\n",
    "y_test = test_dataset[[\"guten_genre\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(X, Y, clf, majority=\"Literary\"):\n",
    "    X=np.take(X, np.where(Y!=\"Literary\")[0], axis=0)\n",
    "    Y=np.take(Y, np.where(Y!=\"Literary\")[0], axis=0)\n",
    "    return(np.mean(clf.predict(X) == Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Classification with Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7228915662650602\n",
      "0.02127659574468085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lreg = LogisticRegression(max_iter=100000).fit(x_train, y_train)\n",
    "print(lreg.score(x_test, y_test))\n",
    "print(sensitivity(x_test, y_test['guten_genre'], lreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4126506024096386\n",
      "0.3617021276595745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb = nb.fit(x_train, y_train)\n",
    "print(nb.score(x_test, y_test))\n",
    "print(sensitivity(x_test, y_test['guten_genre'], nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Classification with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7168674698795181\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(kernel='linear',gamma='auto'))\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.score(x_test, y_test))\n",
    "print(sensitivity(x_test, y_test['guten_genre'], clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:916: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000).fit(x_train, y_train)\n",
    "print(nn.score(x_test, y_test))\n",
    "print(sensitivity(x_test, y_test['guten_genre'], nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
